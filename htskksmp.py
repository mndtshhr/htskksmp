import streamlit as st
import pandas as pd
import datetime
import re
import html
import zipfile
from io import BytesIO

# ---------------------------------------------------------
# å®šæ•°ãƒ»è¨­å®š
# ---------------------------------------------------------
st.set_page_config(
    page_title="ç™ºæ³¨ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã‚¢ãƒ—ãƒª",
    page_icon="ğŸ“¦",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã‚«ãƒ©ãƒ åå®šç¾©
COL_DATE = "date"
COL_DEPT = "department"
COL_JAN = "jan"
COL_NAME = "product_name"
COL_QTY = "quantity"
COL_PRICE = "unit_price"
COL_PROMO = "promotion"
COL_AMOUNT = "total_amount"

# ---------------------------------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ---------------------------------------------------------

def clean_jan(jan_val):
    s = str(jan_val).strip()
    s = s.lstrip("'")
    s = re.sub(r'\.0$', '', s)
    return s

def clean_dept(dept_val):
    try:
        return str(int(float(dept_val))).zfill(3)
    except (ValueError, TypeError):
        return "000"

def parse_date_str(date_str, default_year=None):
    if default_year is None:
        default_year = datetime.date.today().year
        
    s = str(date_str).strip()
    if not s or s.lower() == 'nan': return None
    # 8æ¡æ•°å€¤ (YYYYMMDD)
    if re.match(r'^\d{8}$', s):
        try: return datetime.datetime.strptime(s, '%Y%m%d').date()
        except ValueError: pass
    # M/D å½¢å¼
    m = re.match(r'(\d{1,2})/(\d{1,2})', s)
    if m:
        month, day = map(int, m.groups())
        try: return datetime.date(default_year, month, day)
        except ValueError: pass
    # æ¨™æº–å½¢å¼
    try: return pd.to_datetime(s).date()
    except: pass
    return None

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """ã‚«ãƒ©ãƒ åã®è¡¨è¨˜ã‚†ã‚Œã‚’çµ±ä¸€ã™ã‚‹"""
    col_map = {
        'ç´å“æ—¥': COL_DATE, 'ç´å“äºˆå®šæ—¥': COL_DATE, 'æ—¥ä»˜': COL_DATE,
        'éƒ¨é–€': COL_DEPT, 'éƒ¨é–€ã‚³ãƒ¼ãƒ‰': COL_DEPT, 'éƒ¨é–€CD': COL_DEPT,
        'å•†å“ã‚³ãƒ¼ãƒ‰': COL_JAN, 'JANã‚³ãƒ¼ãƒ‰': COL_JAN, 'JAN': COL_JAN, 'å•†å“CD': COL_JAN,
        'å•†å“å': COL_NAME, 'å“å': COL_NAME,
        'ç™ºæ³¨æ•°é‡': COL_QTY, 'æ•°é‡': COL_QTY, 'ç™ºæ³¨æ•°': COL_QTY,
        'å£²å˜ä¾¡': COL_PRICE, 'å˜ä¾¡': COL_PRICE, 'åŸå˜ä¾¡': COL_PRICE, 'å£²ä¾¡': COL_PRICE,
        'ç™ºæ³¨åŒºåˆ†': COL_PROMO, 'è²©ä¿ƒ': COL_PROMO, 'ç‰¹å£²': COL_PROMO
    }
    # ã‚«ãƒ©ãƒ åã‚’æ–‡å­—åˆ—ã«ã—ã¦ç©ºç™½å‰Šé™¤ã—ã¦ã‹ã‚‰ãƒãƒƒãƒ”ãƒ³ã‚°ç¢ºèª
    new_cols = {}
    for c in df.columns:
        c_str = str(c).strip()
        if c_str in col_map:
            new_cols[c] = col_map[c_str]
    
    return df.rename(columns=new_cols)

# ---------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
# ---------------------------------------------------------

def process_format_1(df: pd.DataFrame) -> pd.DataFrame:
    """ODR_RESå½¢å¼ (ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ / 1è¡Œãƒ˜ãƒƒãƒ€ãƒ¼)"""
    # ã‚«ãƒ©ãƒ åã‚’æ­£è¦åŒ–ã—ã¦å¿…é ˆã‚«ãƒ©ãƒ ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    df = normalize_columns(df)
    
    required_cols = {COL_DATE, COL_DEPT, COL_JAN}
    if not required_cols.issubset(df.columns):
        return pd.DataFrame()

    # è¶³ã‚Šãªã„ã‚«ãƒ©ãƒ ãŒã‚ã‚Œã°è£œå®Œ
    if COL_NAME not in df.columns: df[COL_NAME] = ""
    if COL_QTY not in df.columns: df[COL_QTY] = 0
    if COL_PRICE not in df.columns: df[COL_PRICE] = 0
    if COL_PROMO not in df.columns: df[COL_PROMO] = ""

    df[COL_DATE] = df[COL_DATE].apply(lambda x: parse_date_str(x))
    df[COL_DEPT] = df[COL_DEPT].apply(clean_dept)
    df[COL_JAN] = df[COL_JAN].apply(clean_jan)
    df[COL_QTY] = pd.to_numeric(df[COL_QTY], errors='coerce').fillna(0)
    df[COL_PRICE] = pd.to_numeric(df[COL_PRICE], errors='coerce').fillna(0)
    df[COL_PROMO] = df[COL_PROMO].fillna("").astype(str).replace(['nan', 'None'], '')
    
    cols = [COL_DATE, COL_DEPT, COL_JAN, COL_NAME, COL_QTY, COL_PRICE, COL_PROMO]
    return df[cols].dropna(subset=[COL_DATE])

def process_format_2_from_df(df: pd.DataFrame) -> pd.DataFrame:
    """OrderCheckListå½¢å¼ (ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ / 2è¡Œãƒ˜ãƒƒãƒ€ãƒ¼)"""
    new_cols = []
    last_top = None
    
    for top, bottom in df.columns:
        if "Unnamed" not in str(top) and "é€±åˆè¨ˆ" not in str(top):
            last_top = top
        final_top = last_top if "Unnamed" in str(top) else top
        new_cols.append((final_top, bottom))
    
    df.columns = pd.MultiIndex.from_tuples(new_cols)
    
    fixed_col_map = {}
    date_cols = []
    
    for top, bottom in new_cols:
        if "Unnamed" in str(bottom):
            fixed_col_map[(top, bottom)] = top
        elif top is not None and "é€±åˆè¨ˆ" not in str(top):
            if top not in date_cols: date_cols.append(top)
    
    records = []
    for _, row in df.iterrows():
        base_info = {name: row[col_key] for col_key, name in fixed_col_map.items()}
        jan = base_info.get('JANã‚³ãƒ¼ãƒ‰')
        
        if pd.isna(jan): continue

        for date_str in date_cols:
            if not date_str or date_str == "nan": continue
            
            qty = pd.to_numeric(row.get((date_str, 'æ•°é‡')), errors='coerce')
            if pd.isna(qty): continue
            
            price = pd.to_numeric(row.get((date_str, 'å£²ä¾¡')), errors='coerce')
            promo_val = row.get((date_str, 'è²©ä¿ƒ'))
            promo_str = str(promo_val) if not pd.isna(promo_val) else ""
            
            record = {
                COL_DATE: parse_date_str(date_str),
                COL_DEPT: clean_dept(base_info.get('éƒ¨é–€', '000')),
                COL_JAN: clean_jan(jan),
                COL_NAME: base_info.get('å•†å“å', ''),
                COL_QTY: qty,
                COL_PRICE: price,
                COL_PROMO: promo_str
            }
            records.append(record)
            
    return pd.DataFrame(records)

def load_data(uploaded_file) -> pd.DataFrame:
    """
    ã€ã‚¹ãƒãƒ›å¯¾å¿œå¼·åŒ–ç‰ˆã€‘
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€åˆã«ãƒ¡ãƒ¢ãƒªã«å®Œå…¨å±•é–‹ã—ã¦ã‹ã‚‰è§£æã™ã‚‹ã“ã¨ã§ã€
    ãƒ¢ãƒã‚¤ãƒ«ãƒ–ãƒ©ã‚¦ã‚¶ç‰¹æœ‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿æ¶ˆå¤±ã‚„ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¨ãƒ©ãƒ¼ã‚’é˜²ã
    """
    if uploaded_file is None: return pd.DataFrame()
    
    # 1. ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™ (ã‚¹ãƒãƒ›å¯¾å¿œã§å¿…é ˆ)
    uploaded_file.seek(0)
    
    # 2. ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’å…¨ã¦ãƒ¡ãƒ¢ãƒª(bytes)ã«èª­ã¿è¾¼ã‚€
    try:
        file_content = uploaded_file.read()
    except Exception:
        return pd.DataFrame()

    # 3. è©¦è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
    encodings = ['cp932', 'utf-8-sig', 'utf-8', 'shift_jis']
    header_candidates = [0, 1, 2, 3, 4]

    # 4. ãƒ¡ãƒ¢ãƒªä¸Šã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ç·å½“ãŸã‚Šè§£æ
    for enc in encodings:
        for header_row in header_candidates:
            try:
                # æ¯å›æ–°ã—ã„BytesIOã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½œæˆã™ã‚‹ï¼ˆãƒã‚¤ãƒ³ã‚¿å¹²æ¸‰ã‚’é˜²ããŸã‚ï¼‰
                stream = BytesIO(file_content)
                
                # --- ãƒ‘ã‚¿ãƒ¼ãƒ³1: é€šå¸¸ã®CSV (Format 1) ---
                try:
                    df = pd.read_csv(stream, header=header_row, encoding=enc, encoding_errors='replace')
                    temp_df = normalize_columns(df)
                    # å¿…é ˆã‚«ãƒ©ãƒ ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if {COL_DATE, COL_DEPT, COL_JAN}.issubset(temp_df.columns):
                        return process_format_1(df)
                except Exception:
                    pass 

                # --- ãƒ‘ã‚¿ãƒ¼ãƒ³2: ãƒãƒˆãƒªãƒƒã‚¯ã‚¹CSV (Format 2) ---
                stream.seek(0) # ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½ç½®ãƒªã‚»ãƒƒãƒˆ
                try:
                    df_matrix = pd.read_csv(stream, header=[header_row, header_row+1], encoding=enc, encoding_errors='replace')
                    cols_str = str(df_matrix.columns)
                    if ("JAN" in cols_str or "å•†å“" in cols_str) and ("éƒ¨é–€" in cols_str):
                        res = process_format_2_from_df(df_matrix)
                        if not res.empty: return res
                except Exception:
                    pass

            except Exception:
                continue 

    # å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³å¤±æ•—
    return pd.DataFrame()

# ---------------------------------------------------------
# CSVç”Ÿæˆãƒ»POPç”Ÿæˆ
# ---------------------------------------------------------

def create_matrix_csv(df: pd.DataFrame) -> bytes:
    if df.empty: return b""
    
    meta_df = df.groupby(COL_JAN).agg({
        COL_DEPT: 'first',
        COL_NAME: 'first',
        COL_PRICE: 'max',
        COL_PROMO: 'first'
    })

    pivot_df = df.pivot_table(
        index=COL_JAN,
        columns=COL_DATE, 
        values=COL_QTY, 
        aggfunc='sum', 
        fill_value=0
    )
    
    result_df = pd.concat([meta_df, pivot_df], axis=1).reset_index()

    date_cols = sorted([c for c in result_df.columns if isinstance(c, (datetime.date, datetime.datetime))])
    
    result_df['åˆè¨ˆæ•°é‡'] = result_df[date_cols].sum(axis=1)
    result_df['åˆè¨ˆé‡‘é¡'] = result_df['åˆè¨ˆæ•°é‡'] * result_df[COL_PRICE]

    col_map = {COL_DEPT: 'éƒ¨é–€', COL_JAN: 'JAN', COL_NAME: 'å•†å“å', COL_PRICE: 'å˜ä¾¡', COL_PROMO: 'è²©ä¿ƒ'}
    date_col_map = {d: d.strftime('%Y/%m/%d') for d in date_cols}
    result_df = result_df.rename(columns={**col_map, **date_col_map})
    
    base_cols = ['éƒ¨é–€', 'JAN', 'å•†å“å', 'å˜ä¾¡']
    date_str_cols = [d.strftime('%Y/%m/%d') for d in date_cols]
    final_cols = base_cols + date_str_cols + ['åˆè¨ˆæ•°é‡', 'åˆè¨ˆé‡‘é¡', 'è²©ä¿ƒ']
    
    existing_cols = [c for c in final_cols if c in result_df.columns]
    result_df = result_df[existing_cols]
    result_df['JAN'] = "'" + result_df['JAN'].astype(str)

    csv_buffer = BytesIO()
    result_df.to_csv(csv_buffer, index=False, encoding='utf_8_sig')
    return csv_buffer.getvalue()

def generate_svg(row, daily_qty_map, start_date):
    dept = row[COL_DEPT]
    jan = row[COL_JAN]
    name = html.escape(str(row[COL_NAME]))
    price = row[COL_PRICE]
    total_qty = row[COL_QTY]
    total_amount = row[COL_AMOUNT]
    promo = str(row[COL_PROMO]) if row[COL_PROMO] else ""
    
    fc = "1F"
    if total_amount >= 100000: fc = "5F"
    elif total_amount >= 50000: fc = "4F"
    elif total_amount >= 20000: fc = "3F"
    elif total_amount >= 5000: fc = "2F"
    
    is_sale = False
    if promo and ("ç‰¹å£²" in promo or "ã‚»ãƒ¼ãƒ«" in promo or "ã‚¹ãƒ" in promo):
        is_sale = True
    
    clr = "#ef4444" if is_sale else "#334155"
    bg = "#fef2f2" if is_sale else "#f8fafc"
    
    calendar_svg_parts = []
    current_d = start_date
    for i in range(7):
        d_str = f"{current_d.month}/{current_d.day}"
        qty = daily_qty_map.get(current_d, 0)
        fill_col = "#fff" if i % 2 == 0 else "#f9fafb"
        text_fill = "#000" if qty > 0 else "#d1d5db"
        x_pos = 5 + (i * 84)
        part = f"""<g transform="translate({x_pos}, 355)"><rect width="84" height="80" fill="{fill_col}" stroke="#e2e8f0"/><text x="42" y="20" font-family="sans-serif" font-size="12" fill="#64748b" text-anchor="middle">{d_str}</text><text x="42" y="60" font-family="sans-serif" font-size="26" fill="{text_fill}" font-weight="bold" text-anchor="middle">{int(qty)}</text></g>"""
        calendar_svg_parts.append(part)
        current_d += datetime.timedelta(days=1)
    
    calendar_svg = "".join(calendar_svg_parts)
    svg_content = f"""<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 440" style="background:#fff;"><rect x="5" y="5" width="590" height="430" fill="white" stroke="{clr}" stroke-width="6"/><rect x="5" y="5" width="590" height="65" fill="{bg}"/><line x1="200" y1="5" x2="200" y2="70" stroke="{clr}" stroke-width="2"/><line x1="400" y1="5" x2="400" y2="70" stroke="{clr}" stroke-width="2"/><line x1="5" y1="70" x2="595" y2="70" stroke="{clr}" stroke-width="2"/><text x="102" y="45" font-family="sans-serif" font-size="28" font-weight="900" text-anchor="middle" fill="{clr}">{promo if promo else 'é€šå¸¸'}</text><text x="215" y="25" font-family="sans-serif" font-size="12" fill="#64748b">éƒ¨é–€</text><text x="215" y="55" font-family="sans-serif" font-size="24" font-weight="bold" fill="#1e293b">{dept}</text><text x="415" y="25" font-family="sans-serif" font-size="12" fill="#64748b">ãƒ•ã‚§ã‚¤ã‚¹æ•°</text><text x="500" y="55" font-family="sans-serif" font-size="40" font-weight="900" text-anchor="middle" fill="{clr}">{fc}</text><text x="25" y="105" font-family="sans-serif" font-size="12" fill="#64748b">JAN CODE</text><text x="25" y="145" font-family="monospace" font-size="40" font-weight="bold" letter-spacing="4" fill="#1e293b">{jan}</text><text x="25" y="185" font-family="sans-serif" font-size="34" font-weight="900" fill="#000">{name}</text><line x1="5" y1="205" x2="595" y2="205" stroke="#e2e8f0" stroke-width="2"/><text x="25" y="235" font-family="sans-serif" font-size="12" fill="#64748b">å˜ä¾¡</text><text x="25" y="275" font-family="sans-serif" font-size="32" font-weight="bold">Â¥ {int(price):,}</text><text x="25" y="315" font-family="sans-serif" font-size="12" fill="#64748b">åˆè¨ˆè¦‹è¾¼é¡</text><text x="25" y="345" font-family="sans-serif" font-size="28" font-weight="bold" fill="{clr}">Â¥ {int(total_amount):,}</text><rect x="340" y="215" width="240" height="130" rx="8" fill="#f1f5f9"/><text x="360" y="245" font-family="sans-serif" font-size="14" font-weight="bold" fill="#475569">åˆè¨ˆç‚¹æ•°</text><text x="460" y="325" font-family="sans-serif" font-size="90" font-weight="900" text-anchor="middle" fill="#000">{int(total_qty)}</text><text x="560" y="325" font-family="sans-serif" font-size="20" font-weight="bold" text-anchor="end" fill="#475569">ç‚¹</text>{calendar_svg}</svg>"""
    return svg_content

def create_pop_zip(agg_df, raw_df, start_date) -> bytes:
    zip_buffer = BytesIO()
    daily_map = {}
    temp_df = raw_df[[COL_JAN, COL_DATE, COL_QTY]].copy()
    temp_df[COL_QTY] = pd.to_numeric(temp_df[COL_QTY], errors='coerce').fillna(0)
    grouped = temp_df.groupby([COL_JAN, COL_DATE])[COL_QTY].sum().reset_index()
    for _, r in grouped.iterrows():
        j = r[COL_JAN]; d = r[COL_DATE]; q = r[COL_QTY]
        if j not in daily_map: daily_map[j] = {}
        daily_map[j][d] = q

    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        for _, row in agg_df.iterrows():
            jan = row[COL_JAN]; dept = row[COL_DEPT]
            item_daily_map = daily_map.get(jan, {})
            svg_str = generate_svg(row, item_daily_map, start_date)
            safe_jan = re.sub(r'[\\/:*?"<>|]', '', str(jan))
            safe_dept = re.sub(r'[\\/:*?"<>|]', '', str(dept))
            zf.writestr(f"{safe_dept}_{safe_jan}.svg", svg_str.encode("utf-8"))
    return zip_buffer.getvalue()

# ---------------------------------------------------------
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“
# ---------------------------------------------------------

def main():
    st.title("ğŸ“¦ ç™ºæ³¨ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã‚¢ãƒ—ãƒª")

    # ----------------------------------------
    # LINEãƒ–ãƒ©ã‚¦ã‚¶å¯¾ç­–ã®æ¡ˆå†…
    # ----------------------------------------
    st.markdown("""
    <style>
    .line-warning {
        background-color: #f0f2f6; 
        padding: 15px; 
        border-radius: 8px; 
        margin-bottom: 25px; 
        border-left: 6px solid #ff4b4b;
    }
    .line-warning h4 { margin: 0 0 10px 0; color: #ff4b4b; }
    .line-warning p { margin: 0; font-size: 14px; color: #31333F; line-height: 1.6; }
    </style>
    <div class="line-warning">
        <h4>âš ï¸ LINEã‹ã‚‰é–‹ã„ã¦ã„ã‚‹æ–¹ã¸</h4>
        <p><b>LINEå†…è”µãƒ–ãƒ©ã‚¦ã‚¶ã§ã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒåå¿œã—ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚</b><br>
        åå¿œã—ãªã„å ´åˆã¯ã€å³ä¸Šã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆï¸™ã¾ãŸã¯â†—ï¸ï¼‰ã‹ã‚‰ã€Œãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ãã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚</p>
    </div>
    """, unsafe_allow_html=True)

    # ----------------------------------------
    # 1. ãƒ‡ãƒ¼ã‚¿èª­è¾¼ã¨ãƒ•ã‚£ãƒ«ã‚¿è¨­å®š (Expanderã«é›†ç´„)
    # ----------------------------------------
    with st.expander("ğŸ› ï¸ ãƒ‡ãƒ¼ã‚¿èª­è¾¼ãƒ»ãƒ•ã‚£ãƒ«ã‚¿è¨­å®š", expanded=True):
        st.caption("Step 1: ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        uploaded_files = st.file_uploader(
            "CSV/TXTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", 
            type=["csv", "txt"], 
            accept_multiple_files=True
        )
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å‡¦ç†
        all_data = []
        if uploaded_files:
            for f in uploaded_files:
                df = load_data(f)
                if not df.empty:
                    all_data.append(df)
                    st.success(f"OK: {f.name} ({len(df)}è¡Œ)")
                else:
                    st.error(f"NG: {f.name} (èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ)")

        # ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ãƒ•ã‚£ãƒ«ã‚¿é …ç›®ã‚’è¡¨ç¤º
        if all_data:
            master_df = pd.concat(all_data, ignore_index=True)
            master_df[COL_AMOUNT] = master_df[COL_QTY] * master_df[COL_PRICE]
            
            st.markdown("---")
            st.caption("Step 2: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")

            # 1. æœŸé–“è¨­å®š
            min_date = master_df[COL_DATE].min()
            max_date = master_df[COL_DATE].max()
            if pd.isna(min_date): min_date = datetime.date.today()
            if pd.isna(max_date): max_date = datetime.date.today()
            
            date_range = st.slider(
                "æœŸé–“ã‚’æŒ‡å®š",
                min_value=min_date,
                max_value=max_date,
                value=(min_date, max_date),
                format="MM/DD"
            )
            start_d, end_d = date_range

            # 2. éƒ¨é–€è¨­å®š
            dept_options = sorted(master_df[COL_DEPT].unique())
            if 'selected_depts' not in st.session_state:
                st.session_state.selected_depts = dept_options

            def select_all_depts(): st.session_state.selected_depts = dept_options
            
            st.button("å…¨éƒ¨é–€ã‚’é¸æŠ", on_click=select_all_depts, use_container_width=True)
            selected_depts = st.multiselect("éƒ¨é–€ã‚’æŒ‡å®š", dept_options, key="selected_depts")

            # 3. è²©ä¿ƒè¨­å®š
            unique_promos = sorted(list(set(master_df[COL_PROMO].astype(str).unique())))
            promo_options = [p for p in unique_promos if p.strip()]
            if "" in unique_promos or "nan" in unique_promos:
                if "" not in promo_options: promo_options.append("")
            
            if 'selected_promos' not in st.session_state:
                st.session_state.selected_promos = promo_options
                
            def select_all_promos(): st.session_state.selected_promos = promo_options

            st.button("å…¨è²©ä¿ƒã‚¿ã‚¤ãƒ—ã‚’é¸æŠ", on_click=select_all_promos, use_container_width=True)
            selected_promos = st.multiselect("è²©ä¿ƒã‚¿ã‚¤ãƒ—ã‚’æŒ‡å®š", promo_options, key="selected_promos")

            # 4. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
            search_text = st.text_area("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ (å•†å“åãƒ»JAN)", height=68, placeholder="ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§è¤‡æ•°å¯")
            
        else:
            st.info("ã¾ãšã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ğŸ‘†")
            st.stop() # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã“ã“ã§å‡¦ç†ã‚’æ­¢ã‚ã‚‹

    # -------------------------------------------------
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ­ã‚¸ãƒƒã‚¯é©ç”¨
    # -------------------------------------------------
    mask = (
        (master_df[COL_DATE] >= start_d) & 
        (master_df[COL_DATE] <= end_d) &
        (master_df[COL_DEPT].isin(selected_depts))
    )
    filtered_df = master_df[mask].copy()

    if selected_promos:
        filtered_df = filtered_df[filtered_df[COL_PROMO].astype(str).isin(selected_promos)]
    elif len(promo_options) > 0:
        filtered_df = filtered_df.iloc[0:0]

    if search_text:
        keywords = [k for k in re.split(r'[,\s\n\u3000]+', search_text) if k]
        if keywords:
            match_condition = pd.Series([False] * len(filtered_df), index=filtered_df.index)
            for k in keywords:
                if k.isdigit():
                    match_condition |= (filtered_df[COL_JAN] == k)
                match_condition |= filtered_df[COL_JAN].astype(str).str.contains(k, na=False)
                match_condition |= filtered_df[COL_NAME].astype(str).str.contains(k, na=False)
            filtered_df = filtered_df[match_condition]

    # -------------------------------------------------
    # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
    # -------------------------------------------------
    agg_view = filtered_df.groupby(COL_JAN, as_index=False).agg({
        COL_DEPT: 'first', COL_NAME: 'first', COL_PRICE: 'max', 
        COL_QTY: 'sum', COL_AMOUNT: 'sum', COL_PROMO: 'first'
    }).sort_values(by=COL_QTY, ascending=False)

    st.subheader("ğŸ“Š é›†è¨ˆçµæœ")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    m1, m2, m3 = st.columns(3)
    m1.metric("åˆè¨ˆé‡‘é¡", f"Â¥{agg_view[COL_AMOUNT].sum():,.0f}")
    m2.metric("ç·æ•°é‡", f"{agg_view[COL_QTY].sum():,.0f}")
    m3.metric("ã‚¢ã‚¤ãƒ†ãƒ ", f"{len(agg_view)}å“")

    # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
    st.dataframe(
        agg_view,
        column_config={
            COL_DEPT: "éƒ¨é–€", COL_JAN: "JAN", COL_NAME: "å•†å“å",
            COL_PRICE: st.column_config.NumberColumn("å˜ä¾¡", format="Â¥%d"),
            COL_QTY: st.column_config.NumberColumn("æ•°é‡", format="%d"),
            COL_AMOUNT: st.column_config.NumberColumn("é‡‘é¡", format="Â¥%d"),
            COL_PROMO: "è²©ä¿ƒ"
        },
        use_container_width=True, hide_index=True, height=300
    )

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚¨ãƒªã‚¢
    st.markdown("---")
    st.subheader("ğŸ“¤ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    csv = create_matrix_csv(filtered_df)
    if csv:
        st.download_button(
            label="ğŸ“„ ãƒãƒˆãƒªãƒƒã‚¯ã‚¹CSVã‚’ä¿å­˜",
            data=csv,
            file_name=f"Order_{datetime.datetime.now():%Y%m%d}.csv",
            mime="text/csv",
            use_container_width=True
        )
    
    if not agg_view.empty:
        pop = create_pop_zip(agg_view, filtered_df, start_d)
        st.download_button(
            label="ğŸ¨ POPç”»åƒã‚’ä¸€æ‹¬ä¿å­˜ (ZIP)",
            data=pop,
            file_name=f"POP_{datetime.datetime.now():%Y%m%d}.zip",
            mime="application/zip",
            type="primary",
            use_container_width=True
        )

if __name__ == "__main__":
    main()
